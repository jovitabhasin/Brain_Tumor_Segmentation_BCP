{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ec774482",
      "metadata": {
        "id": "ec774482"
      },
      "source": [
        "# PyTorch Basics Notebook\n",
        "### Introduction to Tensors, Datasets, DataLoaders, CNNs, and U‑Net Building Blocks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a18ac4da",
      "metadata": {
        "id": "a18ac4da"
      },
      "source": [
        "## Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7b9c5b00",
      "metadata": {
        "id": "7b9c5b00"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00d428d4",
      "metadata": {
        "id": "00d428d4"
      },
      "source": [
        "## PyTorch Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "78a7df20",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78a7df20",
        "outputId": "0f32e3d0-9742-4e86-c66d-51f23f23e6db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3.])\n",
            "tensor([1.2730, 0.1289, 0.1756])\n",
            "Addition: tensor([2.2730, 2.1289, 3.1756])\n",
            "Mean: tensor(2.)\n"
          ]
        }
      ],
      "source": [
        "# Creating tensors\n",
        "x = torch.tensor([1.0, 2.0, 3.0])\n",
        "y = torch.randn(3)  # random tensor\n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "\n",
        "# Tensor operations\n",
        "print('Addition:', x + y)\n",
        "print('Mean:', x.mean())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd9b5ec7",
      "metadata": {
        "id": "fd9b5ec7"
      },
      "source": [
        "## Autograd Basics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e818b4c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e818b4c4",
        "outputId": "858d4032-ffef-4823-cad3-9b324aa0ecbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4., 6.])\n"
          ]
        }
      ],
      "source": [
        "# Enable gradient tracking\n",
        "a = torch.tensor([2.0, 3.0], requires_grad=True)\n",
        "b = (a * a).sum()\n",
        "b.backward()\n",
        "print(a.grad)  # derivative of x^2 is 2x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7817f725",
      "metadata": {
        "id": "7817f725"
      },
      "source": [
        "## Custom PyTorch Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aec99e82",
      "metadata": {
        "id": "aec99e82"
      },
      "source": [
        "We simulate MRI-like slices using random arrays just for practice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8bce6e38",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bce6e38",
        "outputId": "cfe190d4-f0f3-4a1f-f501-17990af7e40e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 64, 64]), torch.Size([1, 64, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "class RandomMRIDataset(Dataset):\n",
        "    def __init__(self, length=100):\n",
        "        self.length = length\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = torch.randn(1, 64, 64)      # fake MRI slice\n",
        "        mask = (torch.randn(1, 64, 64) > 0).float()  # fake mask\n",
        "        return image, mask\n",
        "\n",
        "dataset = RandomMRIDataset()\n",
        "img, msk = dataset[0]\n",
        "img.shape, msk.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9236c5f0",
      "metadata": {
        "id": "9236c5f0"
      },
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f729fd41",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f729fd41",
        "outputId": "79d849ec-0f5a-49a1-e4a3-7f104da97135"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 1, 64, 64]) torch.Size([8, 1, 64, 64])\n"
          ]
        }
      ],
      "source": [
        "loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "for images, masks in loader:\n",
        "    print(images.shape, masks.shape)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12ce9109",
      "metadata": {
        "id": "12ce9109"
      },
      "source": [
        "## Building a Simple CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "936aaf0c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "936aaf0c",
        "outputId": "47bfbaff-6b4d-4cab-9146-1540530c22e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleCNN(\n",
            "  (encoder): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU()\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=8192, out_features=1, bias=True)\n",
            "    (2): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32 * 16 * 16, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "model = SimpleCNN()\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfdfc0bc",
      "metadata": {
        "id": "dfdfc0bc"
      },
      "source": [
        "## Training Loop Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3394de56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3394de56",
        "outputId": "cb4cacf6-b606-466a-e70b-1bd7b268c743"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.0000\n",
            "Epoch 2, Loss: 0.0000\n"
          ]
        }
      ],
      "source": [
        "model = SimpleCNN()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "for epoch in range(2):\n",
        "    for images, masks in loader:\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(images)\n",
        "        loss = criterion(preds, torch.zeros_like(preds))  # dummy target\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1abb7bde",
      "metadata": {
        "id": "1abb7bde"
      },
      "source": [
        "## U‑Net Building Blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a8e2cbb4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8e2cbb4",
        "outputId": "bdff3697-8552-42cb-cc48-1df6b2add7a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 128, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "def conv_block(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "sample = torch.randn(1, 1, 128, 128)\n",
        "block = conv_block(1, 16)\n",
        "output = block(sample)\n",
        "output.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0dd9bb0",
      "metadata": {
        "id": "b0dd9bb0"
      },
      "source": [
        "## Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d01b3bb",
      "metadata": {
        "id": "4d01b3bb"
      },
      "source": [
        "\n",
        "1. Modify `RandomMRIDataset` to return a resized (128×128) slice using interpolation.  \n",
        "2. Add another convolution layer to `SimpleCNN` and observe how the model size changes.  \n",
        "3. Implement a small encoder-decoder network (mini U-Net) using `conv_block`.  \n",
        "4. Write a custom Dice Loss function in PyTorch.  \n",
        "5. Train the CNN on the random dataset and plot the loss curve using matplotlib.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4b6cd35",
        "outputId": "2c2ce8b1-9238-4025-9a1e-23f874289a1d"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class RandomMRIDataset(Dataset):\n",
        "    def __init__(self, length=100):\n",
        "        self.length = length\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Generate initial 64x64 image and resize to 128x128\n",
        "        image_64 = torch.randn(1, 64, 64)      # fake MRI slice\n",
        "        image = F.interpolate(image_64.unsqueeze(0), size=(128, 128), mode='bilinear', align_corners=False).squeeze(0)\n",
        "\n",
        "        # Generate initial 64x64 mask and resize to 128x128\n",
        "        mask_64 = (torch.randn(1, 64, 64) > 0).float()  # fake mask\n",
        "        mask = F.interpolate(mask_64.unsqueeze(0), size=(128, 128), mode='bilinear', align_corners=False).squeeze(0)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "dataset = RandomMRIDataset()\n",
        "img, msk = dataset[0]\n",
        "print(f\"Image shape: {img.shape}, Mask shape: {msk.shape}\")"
      ],
      "id": "c4b6cd35",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: torch.Size([1, 128, 128]), Mask shape: torch.Size([1, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7da6996",
        "outputId": "fb244fb6-3293-49e0-b9d0-1ddc32ec44cd"
      },
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            # Added convolution layer\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        # The input size to the linear layer changes because of the added pooling layer.\n",
        "        # Original: 64x64 -> MaxPool2d (32x32) -> MaxPool2d (16x16)\n",
        "        # New: 128x128 (from dataset) -> MaxPool2d (64x64) -> MaxPool2d (32x32) -> MaxPool2d (16x16)\n",
        "        # Output channels for the last conv layer is 64.\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 16 * 16, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "# Instantiate the modified model\n",
        "model_modified = SimpleCNN()\n",
        "\n",
        "# Print the model architecture\n",
        "print(\"\\nModified SimpleCNN Architecture:\")\n",
        "print(model_modified)\n",
        "\n",
        "# Calculate and print the number of trainable parameters\n",
        "total_params = sum(p.numel() for p in model_modified.parameters() if p.requires_grad)\n",
        "print(f\"\\nTotal trainable parameters: {total_params}\")"
      ],
      "id": "a7da6996",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Modified SimpleCNN Architecture:\n",
            "SimpleCNN(\n",
            "  (encoder): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU()\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU()\n",
            "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=16384, out_features=1, bias=True)\n",
            "    (2): Sigmoid()\n",
            "  )\n",
            ")\n",
            "\n",
            "Total trainable parameters: 39681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cca5c676",
        "outputId": "919a67e1-aa9b-4184-868a-aef3a6c42558"
      },
      "source": [
        "class MiniUNet(nn.Module):\n",
        "    def __init__(self, in_channels=1, out_channels=1):\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder path\n",
        "        self.enc1 = conv_block(in_channels, 16)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.enc2 = conv_block(16, 32)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = conv_block(32, 64)\n",
        "\n",
        "        # Decoder path\n",
        "        self.upconv2 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
        "        self.dec2 = conv_block(32 + 32, 32) # Channels from upconv and skip connection\n",
        "        self.upconv1 = nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2)\n",
        "        self.dec1 = conv_block(16 + 16, 16) # Channels from upconv and skip connection\n",
        "\n",
        "        # Output layer\n",
        "        self.final_conv = nn.Conv2d(16, out_channels, kernel_size=1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        enc1_out = self.enc1(x)  # 16x128x128\n",
        "        pool1_out = self.pool1(enc1_out) # 16x64x64\n",
        "\n",
        "        enc2_out = self.enc2(pool1_out) # 32x64x64\n",
        "        pool2_out = self.pool2(enc2_out) # 32x32x32\n",
        "\n",
        "        # Bottleneck\n",
        "        bottleneck_out = self.bottleneck(pool2_out) # 64x32x32\n",
        "\n",
        "        # Decoder\n",
        "        up2_out = self.upconv2(bottleneck_out) # 32x64x64\n",
        "        # Concatenate with skip connection from enc2_out\n",
        "        cat2 = torch.cat([up2_out, enc2_out], dim=1) # (32+32)x64x64\n",
        "        dec2_out = self.dec2(cat2) # 32x64x64\n",
        "\n",
        "        up1_out = self.upconv1(dec2_out) # 16x128x128\n",
        "        # Concatenate with skip connection from enc1_out\n",
        "        cat1 = torch.cat([up1_out, enc1_out], dim=1) # (16+16)x128x128\n",
        "        dec1_out = self.dec1(cat1) # 16x128x128\n",
        "\n",
        "        # Final output\n",
        "        output = self.final_conv(dec1_out)\n",
        "        return self.sigmoid(output)\n",
        "\n",
        "# Instantiate the MiniUNet model\n",
        "mini_unet_model = MiniUNet()\n",
        "print(mini_unet_model)\n",
        "\n",
        "# Test with a dummy input (e.g., 1x128x128)\n",
        "dummy_input = torch.randn(1, 1, 128, 128)\n",
        "output_shape = mini_unet_model(dummy_input).shape\n",
        "print(f\"Output shape for dummy input: {output_shape}\")"
      ],
      "id": "cca5c676",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MiniUNet(\n",
            "  (enc1): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (enc2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (bottleneck): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (upconv2): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (dec2): Sequential(\n",
            "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (upconv1): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (dec1): Sequential(\n",
            "    (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (final_conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "Output shape for dummy input: torch.Size([1, 1, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1693a9b",
        "outputId": "1455ad59-c8fc-4318-c5be-773a5517e9af"
      },
      "source": [
        "def dice_loss(inputs, targets, smooth=1e-6):\n",
        "    # Flatten label and prediction tensors\n",
        "    inputs = inputs.view(-1)\n",
        "    targets = targets.view(-1)\n",
        "\n",
        "    intersection = (inputs * targets).sum()\n",
        "    dice = (2. * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)\n",
        "\n",
        "    return 1 - dice\n",
        "\n",
        "# Test the Dice Loss function with dummy inputs\n",
        "# Example 1: Perfect overlap\n",
        "inputs_perfect = torch.tensor([1.0, 1.0, 0.0, 0.0])\n",
        "targets_perfect = torch.tensor([1.0, 1.0, 0.0, 0.0])\n",
        "loss_perfect = dice_loss(inputs_perfect, targets_perfect)\n",
        "print(f\"Dice Loss (perfect overlap): {loss_perfect:.4f}\")\n",
        "\n",
        "# Example 2: No overlap\n",
        "inputs_no_overlap = torch.tensor([1.0, 1.0, 0.0, 0.0])\n",
        "targets_no_overlap = torch.tensor([0.0, 0.0, 1.0, 1.0])\n",
        "loss_no_overlap = dice_loss(inputs_no_overlap, targets_no_overlap)\n",
        "print(f\"Dice Loss (no overlap): {loss_no_overlap:.4f}\")\n",
        "\n",
        "# Example 3: Partial overlap\n",
        "inputs_partial = torch.tensor([1.0, 1.0, 1.0, 0.0])\n",
        "targets_partial = torch.tensor([0.0, 1.0, 1.0, 1.0])\n",
        "loss_partial = dice_loss(inputs_partial, targets_partial)\n",
        "print(f\"Dice Loss (partial overlap): {loss_partial:.4f}\")\n"
      ],
      "id": "f1693a9b",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dice Loss (perfect overlap): 0.0000\n",
            "Dice Loss (no overlap): 1.0000\n",
            "Dice Loss (partial overlap): 0.3333\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}